{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SGhkrMQX9KPn"
   },
   "source": [
    "<table style=\"font-size: 1em; padding: 0; margin: 0;\">\n",
    "\n",
    "<tr style=\"vertical-align: top; padding: 0; margin: 0;background-color: #ffffff\">\n",
    "        <td style=\"vertical-align: top; padding: 0; margin: 0; padding-right: 15px;\">\n",
    "    <p style=\"background: #182AEB; color:#ffffff; text-align:justify; padding: 10px 25px;\">\n",
    "        <strong style=\"font-size: 1.0em;\"><span style=\"font-size: 1.2em;\"><span style=\"color: #ffffff;\">Deep Learning </span> for Satellite Image Classification (Manning Publications)</span><br/>by <em>Daniel Buscombe</em></strong><br/><br/>\n",
    "        <strong>> Chapter 5: Model Optimization </strong><br/>\n",
    "    </p>           \n",
    "        \n",
    "<p style=\"border: 1px solid #182AEB; border-left: 15px solid #182AEB; padding: 10px; text-align:justify;\">\n",
    "    <strong style=\"color: #182AEB\">What you learned in Part 4.</strong>  \n",
    "    <br/>In Part 4, you trained U-Net models to segment water pixels in imagery\n",
    "    </p>\n",
    "    \n",
    "<p style=\"border: 1px solid #ff5733; border-left: 15px solid #ff5733; padding: 10px; text-align:justify;\">\n",
    "    <strong style=\"color: #ff5733\">What you will learn in this Part.</strong>  \n",
    "    <br/>In Part 5, you will optimize the models you made in Part 4. You will first learn how to tune hyper-parameters, add regularization and modify model architectures in several ways, and deal with class imbalance. Then, you will learn how to use a machine learning model known as a ‘fully-connected conditional random field” to refine label images, so labels are as accurate as possible.\n",
    "    </p>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ROJhVuY4_VOB"
   },
   "source": [
    "#### Preliminaries for Colab\n",
    "\n",
    "Like Part 3 and 4 previously, below are some convenience functions for those working on Google Colab with a GPU runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_history = 1\n",
    "load_res_history = 0\n",
    "#load_large_history = 1\n",
    "if load_history or load_res_history:\n",
    "  import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 48789,
     "status": "ok",
     "timestamp": 1572819087100,
     "user": {
      "displayName": "Daniel Buscombe",
      "photoUrl": "",
      "userId": "01832231008732716345"
     },
     "user_tz": 420
    },
    "id": "I-lc86ey-HOb",
    "outputId": "d9e25c96-3e24-41e2-95f8-ced7856f1a46"
   },
   "outputs": [],
   "source": [
    "colab = 0\n",
    "#colab = 1\n",
    "\n",
    "if colab==1:\n",
    "    %tensorflow_version 2.x\n",
    "    !pip install --default-timeout=1000 tensorflow-gpu==2.0   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F8ruWT7u_ZLB"
   },
   "source": [
    "You may have to restart the runtime and/or change runtime type here, if the following doesn't show Tensorflow version 2, and a GPU available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1758,
     "status": "ok",
     "timestamp": 1572819133184,
     "user": {
      "displayName": "Daniel Buscombe",
      "photoUrl": "",
      "userId": "01832231008732716345"
     },
     "user_tz": 420
    },
    "id": "v7gY9Wi2_aHF",
    "outputId": "3a739855-8e83-4a41-e37c-10bfac00f265"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z7i8OMteVsrG"
   },
   "source": [
    "Convenience functions if you need to download example (minimal) imagery sets derived from NWPU and Sentinel-2 cloudless:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pt7x8mRRVs7m"
   },
   "outputs": [],
   "source": [
    "# from https://stackoverflow.com/questions/38511444/python-download-files-from-google-drive-using-url\n",
    "import requests\n",
    "\n",
    "def download_file_from_google_drive(id, destination):\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = { 'id' : id, 'confirm' : token }\n",
    "        response = session.get(URL, params = params, stream = True)\n",
    "\n",
    "    save_response_content(response, destination)    \n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "\n",
    "    return None\n",
    "\n",
    "def save_response_content(response, destination):\n",
    "    CHUNK_SIZE = 32768\n",
    "\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for chunk in response.iter_content(CHUNK_SIZE):\n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)\n",
    "\n",
    "\n",
    "#s2 cloudless imagery\n",
    "file_id = '1iMfIjr_ul49Ghs2ewazjCt8HMPfhY47h'\n",
    "destination = 's2cloudless_imagery.zip'\n",
    "if colab==1:\n",
    "    download_file_from_google_drive(file_id, destination)\n",
    "\n",
    "#s2 cloudless labels\n",
    "file_id = '1c7MpwKVejoUuW9F2UaF_vps8Vq2RZRfR'\n",
    "destination = 's2cloudless_label_imagery.zip'\n",
    "if colab==1:\n",
    "    download_file_from_google_drive(file_id, destination)\n",
    "\n",
    "#nwpu imagery\n",
    "file_id = '1gtuqy1VlU8-M5IEMnmiSuTlI5PxQPnGB'\n",
    "destination = 'nwpu_images.zip'\n",
    "if colab==1:\n",
    "    download_file_from_google_drive(file_id, destination)\n",
    "\n",
    "#nwpu labels\n",
    "file_id = '1W5LGbcYAcFbG5YjLgX_ekBn0u5Rno35x'\n",
    "destination = 'nwpu_label_images.zip'\n",
    "if colab==1:\n",
    "    download_file_from_google_drive(file_id, destination)                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sommbr0GVy_F"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "def unzip(f):\n",
    "    \"\"\"\n",
    "    f = file to be unzipped\n",
    "    \"\"\"    \n",
    "    with zipfile.ZipFile(f, 'r') as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "        \n",
    "if colab==1:\n",
    "    unzip('s2cloudless_imagery.zip')\n",
    "    unzip('s2cloudless_label_imagery.zip')   \n",
    "    unzip('nwpu_images.zip')\n",
    "    unzip('nwpu_label_images.zip')       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oa9K6-E2T4fR"
   },
   "source": [
    "Import the libraries we will need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cvYaMkSR-JKj"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.layers import Concatenate, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import json, os\n",
    "from random import shuffle\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KYgpaO2O9KPr"
   },
   "source": [
    "<table style=\"font-size: 1em; padding: 0; margin: 0;\">\n",
    "\n",
    "<h1 style=\"width: 100%; text-align: left; padding: 0px 25px;\"><small style=\"color: #182AEB;\">\n",
    "    </small><br/>Training tuning strategies</h1>\n",
    "<br/>\n",
    "<p style=\"border-left: 15px solid #182AEB; text-align:justify; padding: 0 10px;\">\n",
    "We will set up a baseline model with no optimization using the NWPU imagery, then explore the following training optimization strategies:\n",
    "<ul>\n",
    "  <li>Building a bigger model with more layers</li>    \n",
    "  <li>Using Early Stopping and Adaptive Learning Rates</li> \n",
    "  <li>Using a bigger model (and dropout)</li> \n",
    "  <li>Using regularization (Batch Normalization)</li> \n",
    "  <li>Using residual connections</li> \n",
    "</ul>\n",
    "</p>\n",
    "        </tr>\n",
    "        </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PsLTcU6OJMAh"
   },
   "source": [
    "#### Getting things set up with a baseline model\n",
    "Zip through all these functions that we defined in the last Part. \n",
    "\n",
    "Like in the last Part, we will define the ```unet``` model, create model training callbacks, and generate augmented imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oVAJUzEt-Iqq"
   },
   "outputs": [],
   "source": [
    "def mean_iou(y_true, y_pred):\n",
    "    yt0 = y_true[:,:,:,0]\n",
    "    yp0 = tf.keras.backend.cast(y_pred[:,:,:,0] > 0.5, 'float32')\n",
    "    inter = tf.math.count_nonzero(tf.logical_and(tf.equal(yt0, 1), tf.equal(yp0, 1)))\n",
    "    union = tf.math.count_nonzero(tf.add(yt0, yp0))\n",
    "    iou = tf.where(tf.equal(union, 0), 1., tf.cast(inter/union, 'float32'))\n",
    "    return iou\n",
    "\n",
    "def unet(sz = (512, 512, 3)):\n",
    "  inputs = Input(sz)\n",
    "  _ = inputs\n",
    "  \n",
    "  #down sampling \n",
    "  f = 8\n",
    "  layers = []\n",
    "  \n",
    "  for i in range(0, 6):\n",
    "    _ = Conv2D(f, 3, activation='relu', padding='same') (_)\n",
    "    _ = Conv2D(f, 3, activation='relu', padding='same') (_)\n",
    "    layers.append(_)\n",
    "    _ = MaxPooling2D() (_)\n",
    "    f = f*2\n",
    "  ff2 = 64 \n",
    "  \n",
    "  #bottleneck \n",
    "  j = len(layers) - 1\n",
    "  _ = Conv2D(f, 3, activation='relu', padding='same') (_)\n",
    "  _ = Conv2D(f, 3, activation='relu', padding='same') (_)\n",
    "  _ = Conv2DTranspose(ff2, 2, strides=(2, 2), padding='same') (_)\n",
    "  _ = Concatenate(axis=3)([_, layers[j]])\n",
    "  j = j -1 \n",
    "  \n",
    "  #upsampling \n",
    "  for i in range(0, 5):\n",
    "    ff2 = ff2//2\n",
    "    f = f // 2 \n",
    "    _ = Conv2D(f, 3, activation='relu', padding='same') (_)\n",
    "    _ = Conv2D(f, 3, activation='relu', padding='same') (_)\n",
    "    _ = Conv2DTranspose(ff2, 2, strides=(2, 2), padding='same') (_)\n",
    "    _ = Concatenate(axis=3)([_, layers[j]])\n",
    "    j = j -1 \n",
    "    \n",
    "  #classification \n",
    "  _ = Conv2D(f, 3, activation='relu', padding='same') (_)\n",
    "  _ = Conv2D(f, 3, activation='relu', padding='same') (_)\n",
    "  outputs = Conv2D(1, 1, activation='sigmoid') (_)\n",
    "  \n",
    "  #model creation \n",
    "  model = Model(inputs=[inputs], outputs=[outputs])\n",
    "  model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = [mean_iou])\n",
    "  \n",
    "  return model \n",
    "\n",
    "model = unet()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nNDTrZom9KPt"
   },
   "outputs": [],
   "source": [
    "# inheritance for training process plot \n",
    "class PlotLearning(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.acc = []\n",
    "        self.val_acc = []\n",
    "        #self.fig = plt.figure()\n",
    "        self.logs = []\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.acc.append(logs.get('mean_iou'))\n",
    "        self.val_acc.append(logs.get('val_mean_iou'))\n",
    "        self.i += 1\n",
    "        print('i=',self.i,'loss=',logs.get('loss'),'val_loss=',logs.get('val_loss'),'mean_iou=',logs.get('mean_iou'),'val_mean_iou=',logs.get('val_mean_iou'))\n",
    "        \n",
    "        #choose a random test image and preprocess\n",
    "        path = np.random.choice(test_files)\n",
    "        infile = f'nwpu_images/data/{path}'\n",
    "        raw = Image.open(infile)\n",
    "        raw = np.array(raw.resize((512, 512)))/255.\n",
    "        raw = raw[:,:,0:3]\n",
    "        \n",
    "        #predict the mask \n",
    "        pred = 255*model.predict(np.expand_dims(raw, 0)).squeeze()\n",
    "        print(np.max(pred))\n",
    "                \n",
    "        #mask post-processing \n",
    "        msk  = (pred>60).astype('int') #100       \n",
    "        msk = np.stack((msk,)*3, axis=-1)\n",
    "        #msk[msk >= 0.5] = 1 \n",
    "        #msk[msk < 0.5] = 0 \n",
    "        \n",
    "        #show the mask and the segmented image \n",
    "        combined = np.concatenate([raw, msk, raw* msk], axis = 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(combined)\n",
    "        plt.show()      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HkJBCYCWM6qi"
   },
   "source": [
    "We use Keras callbacks to implement learning rate decay if the validation loss does not improve for 5 continues epochs. Called \"reduce loss on plateau\"\n",
    "\n",
    "Also, we implement early stopping if the validation loss does not improve for 5 continuous epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fo2ls1vA9KPy"
   },
   "outputs": [],
   "source": [
    "def image_batch_generator(files, batch_size = 32, sz = (512, 512)):\n",
    "  \n",
    "  while True: # this is here because it will be called repeatedly by the training function\n",
    "    \n",
    "    #extract a random subset of files of length \"batch_size\"\n",
    "    batch = np.random.choice(files, size = batch_size)    \n",
    "    \n",
    "    #variables for collecting batches of inputs (x) and outputs (y)\n",
    "    batch_x = []\n",
    "    batch_y = []\n",
    "    \n",
    "    #cycle through each image in the batch\n",
    "    for f in batch:\n",
    "\n",
    "        #preprocess the raw images \n",
    "        rawfile = f'nwpu_images/data/{f}'\n",
    "        raw = Image.open(rawfile)\n",
    "        raw = raw.resize(sz)\n",
    "        raw = np.array(raw)\n",
    "\n",
    "        #check the number of channels because some of the images are RGBA or GRAY\n",
    "        if len(raw.shape) == 2:\n",
    "            raw = np.stack((raw,)*3, axis=-1)\n",
    "\n",
    "        else:\n",
    "            raw = raw[:,:,0:3]\n",
    "            \n",
    "        #get the image dimensions, find the min dimension, then square the image off    \n",
    "        nx, ny, nz = np.shape(raw)\n",
    "        n = np.minimum(nx,ny)\n",
    "        raw = raw[:n,:n,:] \n",
    "            \n",
    "        batch_x.append(raw)\n",
    "        \n",
    "        #get the masks. \n",
    "        maskfile = rawfile.replace('nwpu_images','nwpu_label_images')+'_mask.jpg'\n",
    "        mask = Image.open(maskfile)\n",
    "        # the mask is 3-dimensional so get the max in each channel to flatten to 2D\n",
    "        mask = np.max(np.array(mask.resize(sz)),axis=2)\n",
    "        # water pixels are always greater than 100\n",
    "        mask = (mask>200).astype('int')\n",
    "        \n",
    "        mask = mask[:n,:n]\n",
    "\n",
    "        batch_y.append(mask)\n",
    "\n",
    "    #preprocess a batch of images and masks \n",
    "    batch_x = np.array(batch_x)/255. #divide image by 255 to normalize\n",
    "    batch_y = np.array(batch_y)\n",
    "    batch_y = np.expand_dims(batch_y,3) #add singleton dimension to batch_y\n",
    "\n",
    "    yield (batch_x, batch_y) #yield both the image and the label together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WR_LULokT4ff"
   },
   "source": [
    "We've seen code like the below in the previous Part, setting up batch size, proportion of the dataset to train with, getting randomized lists of test and train file names, and finally setting up generators for model training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-3Fu3vdZ-nsN"
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "prop_train = 0.6\n",
    "\n",
    "all_files = os.listdir('nwpu_images/data')\n",
    "shuffle(all_files)\n",
    "\n",
    "split = int(prop_train * len(all_files))\n",
    "\n",
    "#split into training and testing\n",
    "train_files = all_files[0:split]\n",
    "test_files  = all_files[split:]\n",
    "\n",
    "train_generator = image_batch_generator(train_files, batch_size = batch_size)\n",
    "test_generator  = image_batch_generator(test_files, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2U2y96CiT4fi"
   },
   "source": [
    "A customary check that things worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 695,
     "status": "ok",
     "timestamp": 1572819501376,
     "user": {
      "displayName": "Daniel Buscombe",
      "photoUrl": "",
      "userId": "01832231008732716345"
     },
     "user_tz": 420
    },
    "id": "8rIwVxdIIWEV",
    "outputId": "3e65d04f-eeef-4bf4-e0b9-690f7e88ff60"
   },
   "outputs": [],
   "source": [
    "x, y = next(train_generator)\n",
    "plt.imshow(x[0])\n",
    "plt.imshow(y[0].squeeze(), cmap='gray', alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kCtvJfY6T4fn"
   },
   "source": [
    "<table style=\"font-size: 1em; padding: 0; margin: 0;\">\n",
    "\n",
    "<h1 style=\"width: 100%; text-align: left; padding: 0px 25px;\"><small style=\"color: #182AEB;\">\n",
    "    </small><br/>Optimization strategy: Using Early Stopping<br/>and Adaptive Learning Rates</h1>\n",
    "<br/>\n",
    "<p style=\"border-left: 15px solid #182AEB; text-align:justify; padding: 0 10px;\">\n",
    "    Neural networks can overfit if they train for too long, but it's hard to know how many epochs is too many without a lot of trial and error, which is not efficient. Automatically computing how many training epochs a model needs or, to put it another way, evaluating when to stop training or <em>early stopping</em>, is achieved by monitoring validation loss during training. If loss doesn't improve for a certain number of epochs, called the <em>patience</em>, model training is terminated. Below <em>patience</em> is set to 5. Another common training strategy to prevent overly long training times is to adaptively change the learning rate during model training. This is achieved by starting with a relatively large number and then decreasing it after every training epoch until a specified minimum <em>min_lr</em> at a certain rate of reduction <em>min_delta</em>.</p>\n",
    "        </tr>\n",
    "        </table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ajq5OJsUT4fo"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "01eq594-NkqB"
   },
   "outputs": [],
   "source": [
    "def build_callbacks(filepath, min_delta, min_lr, factor):\n",
    "\n",
    "    earlystop = EarlyStopping(monitor=\"val_loss\", \n",
    "                                  mode=\"min\", patience=5) \n",
    "    \n",
    "    # reduction of learning rate if and when validation scores plateau upon successive epochs\n",
    "    reduceloss_plat = ReduceLROnPlateau(monitor='val_loss', factor=factor, patience=5, \n",
    "                                    verbose=1, mode='auto', min_delta=min_delta, \n",
    "                                    cooldown=5, min_lr=min_lr)\n",
    "\n",
    "    # set checkpoint file \n",
    "    model_checkpoint = ModelCheckpoint(filepath, monitor='val_loss', \n",
    "                                   verbose=0, save_best_only=True, mode='min', \n",
    "                                   save_weights_only = True)\n",
    "        \n",
    "    callbacks = [model_checkpoint, reduceloss_plat, earlystop, PlotLearning()]\n",
    "\n",
    "    return callbacks  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GKPDSbt3T4ft"
   },
   "outputs": [],
   "source": [
    "# a tolerance for the training.\n",
    "min_delta = 0.0001\n",
    "\n",
    "# minimum learning rate (lambda)\n",
    "min_lr = 0.0001\n",
    "\n",
    "# the factor applied to the learning rate when the appropriate triggers are made\n",
    "factor = 0.8\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "filepath = 'unet'+str(batch_size)+'.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 212,
     "status": "ok",
     "timestamp": 1572819509390,
     "user": {
      "displayName": "Daniel Buscombe",
      "photoUrl": "",
      "userId": "01832231008732716345"
     },
     "user_tz": 420
    },
    "id": "haW5J3F1-xax",
    "outputId": "5dd61647-fcd7-4fb9-f83c-84cc6a78834f"
   },
   "outputs": [],
   "source": [
    "train_generator = image_batch_generator(train_files, batch_size = batch_size)\n",
    "test_generator  = image_batch_generator(test_files, batch_size = batch_size)\n",
    "train_steps = len(train_files) //batch_size\n",
    "test_steps = len(test_files) //batch_size\n",
    "print(train_steps)\n",
    "print(test_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1h1kkvccOC8dCd-3vo-Bq0MZ5Jxx-pYuS"
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 69493,
     "status": "ok",
     "timestamp": 1572821080699,
     "user": {
      "displayName": "Daniel Buscombe",
      "photoUrl": "",
      "userId": "01832231008732716345"
     },
     "user_tz": 420
    },
    "id": "Rxoznmh4T4fy",
    "outputId": "7e25f251-4075-4f2b-c435-1711b18c2b98"
   },
   "outputs": [],
   "source": [
    "if load_history:\n",
    "  file_id = '1wIDC0-6ngIoldQr54ss2WdTIf6UT2qfN'\n",
    "  destination = 'opt_model_1_early_hist'\n",
    "  download_file_from_google_drive(file_id, destination)\n",
    "  with open(\"opt_model_1_early_hist\", \"rb\") as file_pi:\n",
    "    history = pickle.load(file_pi)\n",
    "  large_history = history\n",
    "else:\n",
    "  history = model.fit_generator(train_generator,\n",
    "                                epochs = 50, steps_per_epoch = train_steps,\n",
    "                                validation_data = test_generator, \n",
    "                                validation_steps = test_steps,\n",
    "                                callbacks = build_callbacks(filepath, \n",
    "                                                            min_delta, \n",
    "                                                            min_lr, \n",
    "                                                            factor), \n",
    "                                verbose = 0,\n",
    "                                use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g6Q5sqnET4f1"
   },
   "outputs": [],
   "source": [
    "if not load_history:\n",
    "  # save model and history to load or graph later\n",
    "  model.save(\"opt_model_1_early\",save_format=\"h5\")\n",
    "  \n",
    "  import pickle\n",
    "  with open('opt_model_1_early_hist', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)\n",
    "  \n",
    "  del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jmoMd5t7T4gi"
   },
   "source": [
    "<table style=\"font-size: 1em; padding: 0; margin: 0;\">\n",
    "\n",
    "<h1 style=\"width: 100%; text-align: left; padding: 0px 25px;\"><small style=\"color: #182AEB;\">\n",
    "    </small><br/>Optimization strategy: changing model architecture <br/>using residual connections</h1>\n",
    "<br/>\n",
    "<p style=\"border-left: 15px solid #182AEB; text-align:justify; padding: 0 10px;\">\n",
    "A standard approach is to pass the input image goes through multiple convolutions and obtain high-level features. In a network architecture with <em>residual layers</em> or connections, each layer gets to see both the output from the previous layer (standard) as well as the inputs to that layer. So it not only sees the ouputs but also the data used to learn that output\n",
    "</p>\n",
    "        </tr>\n",
    "        </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "566oTTdYT4gj"
   },
   "source": [
    "![](https://cdn-images-1.medium.com/max/1000/1*4wx7szWCBse9-7eemGQJSw.png)\n",
    "\n",
    "Import `Activation` and `Add` layers from keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BUPYE3s5T4gj"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Activation, Add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g7B6b4HWT4gm"
   },
   "source": [
    "Create a new UNet model function. This time we'll use a few convenience functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchnorm_act(x):\n",
    "    x = BatchNormalization()(x)\n",
    "    return Activation(\"relu\")(x)\n",
    "\n",
    "def conv_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    conv = batchnorm_act(x)\n",
    "    return Conv2D(filters, kernel_size, padding=padding, strides=strides)(conv)\n",
    "\n",
    "def bottleneck_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n",
    "    conv = conv_block(conv, filters, kernel_size=kernel_size, padding=padding, strides=strides)\n",
    "    \n",
    "    bottleneck = Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)\n",
    "    bottleneck = batchnorm_act(bottleneck)\n",
    "    \n",
    "    return Add()([conv, bottleneck])\n",
    "\n",
    "def res_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    res = conv_block(x, filters, kernel_size=kernel_size, padding=padding, strides=strides)\n",
    "    res = conv_block(res, filters, kernel_size=kernel_size, padding=padding, strides=1)\n",
    "    \n",
    "    bottleneck = Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)\n",
    "    bottleneck = batchnorm_act(bottleneck)\n",
    "    \n",
    "    return Add()([bottleneck, res])\n",
    "\n",
    "def upsamp_concat_block(x, xskip):\n",
    "    u = UpSampling2D((2, 2))(x)\n",
    "    return Concatenate()([u, xskip])\n",
    "\n",
    "def res_unet(sz, f):\n",
    "    inputs = Input(sz)\n",
    "    \n",
    "    ## downsample  \n",
    "    e1 = bottleneck_block(inputs, f); f = int(f*2)\n",
    "    e2 = res_block(e1, f, strides=2); f = int(f*2)\n",
    "    e3 = res_block(e2, f, strides=2); f = int(f*2)\n",
    "    e4 = res_block(e3, f, strides=2); f = int(f*2)\n",
    "    _ = res_block(e4, f, strides=2)\n",
    "    \n",
    "    ## bottleneck\n",
    "    b0 = conv_block(_, f, strides=1)\n",
    "    _ = conv_block(b0, f, strides=1)\n",
    "    \n",
    "    ## upsample\n",
    "    _ = upsamp_concat_block(_, e4)\n",
    "    _ = res_block(_, f); f = int(f/2)\n",
    "    \n",
    "    _ = upsamp_concat_block(_, e3)\n",
    "    _ = res_block(_, f); f = int(f/2)\n",
    "    \n",
    "    _ = upsamp_concat_block(_, e2)\n",
    "    _ = res_block(_, f); f = int(f/2)\n",
    "    \n",
    "    _ = upsamp_concat_block(_, e1)\n",
    "    _ = res_block(_, f)\n",
    "    \n",
    "    ## classify\n",
    "    outputs = Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(_)\n",
    "    \n",
    "    #model creation \n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "89fLigFvT4gp",
    "outputId": "f7d440da-df06-4a44-c784-fd53f38debc2"
   },
   "outputs": [],
   "source": [
    "model = res_unet((512, 512, 3), 16)\n",
    "model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = [mean_iou])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3gi-3jDDT4gs"
   },
   "source": [
    "Train the model with the residual connections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZlzUHZh6T4gt",
    "outputId": "32c1bc97-774b-41c7-f630-0dfb8f63a1ed"
   },
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "\n",
    "filepath = 'res_unet'+str(batch_size)+'.h5'\n",
    "\n",
    "train_generator = image_batch_generator(train_files, batch_size = batch_size)\n",
    "test_generator  = image_batch_generator(test_files, batch_size = batch_size)\n",
    "train_steps = len(train_files) //batch_size\n",
    "test_steps = len(test_files) //batch_size\n",
    "print(train_steps)\n",
    "print(test_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_res_history:\n",
    "  file_id = ''\n",
    "  destination = 'opt_model_4_res_hist'\n",
    "  download_file_from_google_drive(file_id, destination)\n",
    "  with open(\"opt_model_4_res_hist\", \"rb\") as file_pi:\n",
    "    res_history = pickle.load(file_pi)\n",
    "else:\n",
    "    res_history = model.fit_generator(train_generator, \n",
    "                                      epochs = 100, steps_per_epoch = train_steps,\n",
    "                                      validation_data = test_generator, \n",
    "                                      validation_steps = test_steps,\n",
    "                                      callbacks = build_callbacks(filepath, min_delta, \n",
    "                                                                  min_lr, factor), \n",
    "                                      verbose = 0,\n",
    "                                      use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OzLf-obYT4gx"
   },
   "outputs": [],
   "source": [
    "if not load_res_history:\n",
    "  #save model and history to load or graph later\n",
    "  model.save(\"opt_model_4_res\",save_format=\"h5\")\n",
    "  \n",
    "  with open('opt_model_4_res_hist', 'wb') as file_pi:\n",
    "    pickle.dump(res_history.history, file_pi)# save model and history to load or graph later\n",
    "  \n",
    "  del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B0iAQfM8T4g0"
   },
   "source": [
    "Compare the training histories of the baseline and U-Net with residual layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CriGrS_ZT4g1",
    "outputId": "273c1990-cdcf-4475-9a21-7e25ca082fc2"
   },
   "outputs": [],
   "source": [
    "# summarize history for iou\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(121)\n",
    "if load_history:\n",
    "  plt.plot(history['mean_iou'],'k',lw=1)\n",
    "  plt.plot(history['val_mean_iou'],'r',lw=1)\n",
    "else:\n",
    "  plt.plot(history.history['mean_iou'],'k',lw=1)\n",
    "  plt.plot(history.history['val_mean_iou'],'r',lw=1)\n",
    "plt.ylim(0,1)\n",
    "plt.axhline(y=0.85)\n",
    "plt.title('Baseline IoU')\n",
    "plt.ylabel('IoU')\n",
    "plt.xlabel('Epoch number')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "plt.subplot(122)\n",
    "if load_res_history:\n",
    "    plt.plot(res_history['mean_iou'],'k',lw=1)\n",
    "    plt.plot(res_history['val_mean_iou'],'r',lw=1)\n",
    "else:\n",
    "    plt.plot(res_history.history['mean_iou'],'k',lw=1)\n",
    "    plt.plot(res_history.history['val_mean_iou'],'r',lw=1)    \n",
    "plt.ylim(0,1)\n",
    "plt.axhline(y=0.85)\n",
    "plt.title('Res-UNet IoU')\n",
    "plt.ylabel('IoU')\n",
    "plt.xlabel('Epoch number')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Part5_Optimizing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
